Project File Combination
Generated on: 2024-09-25 12:50:21.280964

Total files: 33
File type counts:
  .py: 9
  .md: 1
  .html: 9
  .js: 1
  .css: 1

File Structure:
../
    .gitignore
    docker-compose.yml
    .dockerignore
    combined_project_files.txt
    database_setup.log
    Dockerfile
    requirements.txt
    app/
        app.py
        docker-compose.yml
        models.py
        secret_key.txt
        generate_password.py
        readme.md
        combined_project_files.txt
        config.json
        data_processing.py
        database_setup.py
        json_validator_multi.py
        json_validator.py
        database_setup.log
        start_docker.sh
        routes.py
        read_pickle.py
        templates/
            search-terms.html
            login.html
            document-detail.html
            document-list.html
            base.html
            database-info.html
            settings.html
            index.html
            error.html
        static/
            script.js
            style.css
    \wsl.localhostUbuntu-22.04homelhymanpaper/

********************************************************************************

File: app/app.py
********************************************************************************

# File: app.py
# Path: railroad_documents_project/app.py

import os
import json
from flask import Flask
from flask_caching import Cache
from flask_session import Session
from database_setup import get_client, get_db, get_collections, get_field_structure
import logging
from logging.handlers import RotatingFileHandler

app = Flask(__name__)

# Configure cache (optional, for performance enhancements)
cache = Cache(app, config={'CACHE_TYPE': 'simple'})

# Setup console logging
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)

# Add the console handler to the app's logger
app.logger.addHandler(console_handler)

# # Setup file-based logging
# if not app.debug:
#     file_handler = RotatingFileHandler('logs/app.log', maxBytes=10240, backupCount=10)
#     file_handler.setLevel(logging.DEBUG)
#     formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
#     file_handler.setFormatter(formatter)
#     app.logger.addHandler(file_handler)

app.logger.setLevel(logging.DEBUG)

# Load configuration
config_path = os.path.join(os.path.dirname(__file__), 'config.json')
with open(config_path) as config_file:
    config = json.load(config_file)

# Add config to app config
app.config['UI_CONFIG'] = config

# Print out the template folder path for debugging
print(f"Template folder path: {app.template_folder}")

# Session configuration
app.config['SESSION_TYPE'] = 'filesystem'
app.config['SESSION_PERMANENT'] = False
app.config['SESSION_USE_SIGNER'] = True
app.config['SESSION_KEY_PREFIX'] = 'historical_document_reader'

def get_secret_key():
    secret_file = os.path.join(app.root_path, 'secret_key.txt')
    if os.path.exists(secret_file):
        with open(secret_file, 'r') as f:
            return f.read().strip()
    else:
        import secrets
        generated_key = secrets.token_hex(16)
        with open(secret_file, 'w') as f:
            f.write(generated_key)
        return generated_key

# Set the secret key
app.secret_key = get_secret_key()

# Initialize extensions
cache = Cache(config={'CACHE_TYPE': 'simple'})
cache.init_app(app)
Session(app)

def load_config():
    """
    Load the configuration from the JSON file.
    This function is called on each request to allow for dynamic UI configuration.
    """
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        return json.load(config_file)

@app.context_processor
def inject_ui_config():
    """
    Inject the UI configuration and field structure into all templates.
    This allows for dynamic UI customization without needing to pass the config to each template.
    """
    app.config['UI_CONFIG'] = load_config()
    client = get_client()
    field_struct = get_field_structure(client)
    return dict(ui_config=app.config['UI_CONFIG'], field_structure=field_struct)

# Import routes after initializing app to avoid circular imports
from routes import *

if __name__ == '__main__':
    # Run the app
    app.run(debug=True)


********************************************************************************

File: app/models.py
********************************************************************************

# No longer necessary since it is NoSQL db. 

# from app import db, ma

# class OCRText(db.Model):
#     __tablename__ = 'ocr_text'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, nullable=False)
#     text = db.Column(db.Text, nullable=False)

#     summary = db.relationship('Summary', back_populates='ocr_text', uselist=False)
#     named_entities = db.relationship('NamedEntity', back_populates='ocr_text')
#     dates = db.relationship('Date', back_populates='ocr_text')
#     monetary_amounts = db.relationship('MonetaryAmount', back_populates='ocr_text')
#     relationships = db.relationship('Relationship', back_populates='ocr_text')
#     document_metadata = db.relationship('DocumentMetadata', back_populates='ocr_text', uselist=False)
#     translation = db.relationship('Translation', back_populates='ocr_text', uselist=False)
#     file_info = db.relationship('FileInfo', back_populates='ocr_text', uselist=False)

# class Summary(db.Model):
#     __tablename__ = 'summary'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     text = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='summary')

# class NamedEntity(db.Model):
#     __tablename__ = 'named_entities'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     entity = db.Column(db.Text, nullable=False)
#     type = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='named_entities')

# class Date(db.Model):
#     __tablename__ = 'dates'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     date = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='dates')

# class MonetaryAmount(db.Model):
#     __tablename__ = 'monetary_amounts'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     amount = db.Column(db.Text, nullable=False)
#     category = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='monetary_amounts')

# class Relationship(db.Model):
#     __tablename__ = 'relationships'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     entity1 = db.Column(db.Text, nullable=False)
#     relationship = db.Column(db.Text, nullable=False)
#     entity2 = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='relationships')

# class DocumentMetadata(db.Model):
#     __tablename__ = 'metadata'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     document_type = db.Column(db.Text, nullable=False)
#     period = db.Column(db.Text, nullable=False)
#     context = db.Column(db.Text, nullable=False)
#     sentiment = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='document_metadata')

# class Translation(db.Model):
#     __tablename__ = 'translation'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     french_text = db.Column(db.Text, nullable=False)
#     english_translation = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='translation')

# class FileInfo(db.Model):
#     __tablename__ = 'file_info'
#     id = db.Column(db.Text, primary_key=True)
#     file = db.Column(db.Text, db.ForeignKey('ocr_text.id'), nullable=False)
#     original_filepath = db.Column(db.Text, nullable=False)

#     ocr_text = db.relationship('OCRText', back_populates='file_info')

# # Add Marshmallow schemas if needed
# class OCRTextSchema(ma.SQLAlchemyAutoSchema):
#     class Meta:
#         model = OCRText


********************************************************************************

File: app/generate_password.py
********************************************************************************

from werkzeug.security import generate_password_hash

actual_password = 'loulou'
method = 'pbkdf2:sha256:260000'

password_hash = generate_password_hash(actual_password, method=method)
print(password_hash)



********************************************************************************

File: app/readme.md
********************************************************************************

# Historical Document Reader

## Description
The Historical Document Reader is a Flask-based web application designed to manage, search, and display historical documents stored in a MongoDB database. It provides an intuitive interface for researchers and historians to access and analyze digitized historical records.

## Repository
The project is hosted on GitHub at:
https://github.com/proflouishyman/nosql_reader

## Features

- Document Management: Data ingestion from JSON files, dynamic field structure discovery
- Search Functionality: Advanced search with multiple fields and logical operators
- Document Viewing: Detailed view with image zoom and pan capabilities
- Data Analysis: Search terms analysis with word and phrase frequency
- User Interface: Customizable UI settings, responsive design
- Data Export: Export search results to CSV
- Security: Basic authentication system with CAPTCHA

## To Do

0. Shift other PC to Docker
0.1. Create flag for list of hidden fields
1. Convert setup process to a part of settings or a new page. It should be able to add to the DB
2. Create login splash page
3. Need to adjust unique search terms to move from a pickle file to part of the MongoDB
4. Address weirdness of base file and index.html. It is unseemly 
5. Reorganize routes.py
6. Add cross-referencing of named entities
7. Restore adding export from list
8. Add "Select all" for export
9. Clean file description to remove extension in title
10. Create a way to do a search and then add that result to the DB
11. Backup and restore database
12. Remove blank fields from JSON expansion
13. Color code sections of JSON expansion
14. Need to implement a sort for the file results, so that this is in order: 	File	Summary
	RDApp-630550Fox053.jpg.json	The document contains a handwritten signature of an individual named M. Johnson, along with the year 1919.
	RDApp-630550Fox072.jpg.json	This document is a surgeon's first report of an accident for the Baltimore & Ohio Railroad-Relief Department. It details an incident involving an individual named E.S. Fry, a laborer, who resides in All Around O. The report notes injuries sustained: a contusion and a cut lip, with the mention of a broken face due to a tool. The probable duration of disablement is stated to be short. Additionally, it provides a brief account of how the accident occurred, indicating involvement with a train.
	RDApp-630550Fox059.jpg.json	The document appears to be a handwritten note addressed to Mr. Martin from someone requesting approval from Dr. Smith, a company surgeon, regarding a matter likely related to medical or health concerns.
	RDApp-630550Fox014.jpg.json	This document is a correspondence from the Office of General Claim Agent of The Baltimore and Ohio Railroad Company, dated December 8, 1920. It refers to a bill from The Peoples Hospital for services rendered to E. L. Fox, a train rider who was injured at Cuyahoga Falls, Ohio, on October 31, 1920. The bill is being sent to Mr. W. J. Dudley, Superintendent of the Relief Department, for voucher processing. The document indicates that Mr. Fox was a member of the Relief Department at the time of his injury. Additionally, there is a note referencing a letter related to this bill dated 16th of December, 1920.
	RDApp-630550Fox062.jpg.json	This document is a telegram from the Baltimore and Ohio Railroad Company to the Superintendent of City Hospital in Akron, Ohio, dated August 5th, 1921. It refers to a bill concerning an individual named E. L. Fox and requests further communication regarding the matter.

## File Structure

```
historical_document_reader/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ routes.py
â”œâ”€â”€ models.py
â”œâ”€â”€ database_setup.py
â”œâ”€â”€ data_processing.py
â”œâ”€â”€ json_validator.py
â”œâ”€â”€ json_validator_multi.py
â”œâ”€â”€ generate_password.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.json
â”œâ”€â”€ secret_key.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js
â”‚   â””â”€â”€ style.css
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ document-detail.html
â”‚   â”œâ”€â”€ document-list.html
â”‚   â”œâ”€â”€ search-terms.html
â”‚   â”œâ”€â”€ database-info.html
â”‚   â”œâ”€â”€ settings.html
â”‚   â”œâ”€â”€ login.html
â”‚   â””â”€â”€ error.html
â”‚
â””â”€â”€ archives/
    â””â”€â”€ [Your archival files go here]
```

## Installation and Setup

1. Clone the repository:
   ```
   git clone https://github.com/proflouishyman/nosql_reader.git
   ```

2. Navigate to the project directory and install dependencies:
   ```
   cd nosql_reader
   pip install -r requirements.txt
   ```

3. Set up MongoDB:
   - Install MongoDB if you haven't already.
   - Start the MongoDB service.
   - Update the connection string in `database_setup.py` if necessary:
     ```python
     client = MongoClient('mongodb://localhost:27017/')
     ```

4. Initialize the database structure:
   ```
   python database_setup.py
   ```

5. Prepare your JSON data:
   - Ensure your historical document data is in JSON format.
   - Place all archival files in the `archives` subdirectory.
   - If your data is in .txt files, use the JSON validator to convert and validate them:
     ```
     python json_validator.py
     ```

6. Ingest data into the database:
   - Update the `data_directory` path in `data_processing.py` to point to your JSON files in the `archives` subdirectory.
   - Run the data processing script:
     ```
     python data_processing.py
     ```

7. Generate a password for admin access (optional):
   ```
   python generate_password.py
   ```

8. Run the application:
   ```
   python app.py
   ```

## Usage

1. Access the application at `http://localhost:5000`.
2. Log in using the generated admin password.
3. Use the search interface to find documents.
4. View search results and document details.
5. Analyze search terms and view database information.
6. Customize the interface in the Settings page.
7. Export results to CSV as needed.

## Docker Setup

Run `run_docker.sh` to install and set up using Docker. If there are problems, install `dos2unix` and then convert the file. Everything runs better in WSL.

MongoDB connection string for Docker setup:
```python
client = MongoClient('mongodb://admin:secret@localhost:27017/')
```

## Maintenance and Updates

- Add new documents by placing JSON files in the `archives` subdirectory and running `data_processing.py`.
- The system automatically adapts to changes in document structure.
- Regularly backup your MongoDB database.

## Troubleshooting

- Verify JSON format for data processing issues.
- Check MongoDB service and connection string for database issues.
- Consult application logs for error messages.

## Main Python Files

- `app.py`: Main application file, initializes Flask app
- `routes.py`: Contains all route handlers and main functionality
- `database_setup.py`: Manages MongoDB connection and CRUD operations
- `data_processing.py`: Handles data ingestion and processing
- `json_validator.py` and `json_validator_multi.py`: Validate and clean JSON files
- `generate_password.py`: Utility for generating admin password

## Contributing

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make changes and commit with descriptive messages.
4. Push changes to your fork.
5. Submit a pull request to the main repository.

## License

[Insert your chosen license here]

## Contact

[Your Name or Organization]
[Contact Information]

********************************************************************************

File: app/data_processing.py
********************************************************************************

# data_processing.py

import os
import json
import re
import hashlib
from database_setup import insert_document, update_field_structure, get_db
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import time
import logging
import argparse
from collections import Counter

# =======================
# Logging Configuration
# =======================

# Create a custom logger
logger = logging.getLogger('DataProcessingLogger')
logger.setLevel(logging.INFO)  # Adjust logging level as needed

# Create handlers
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

file_handler = logging.FileHandler('data_processing.log')
file_handler.setLevel(logging.ERROR)

# Create formatters and add them to handlers
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
file_handler.setFormatter(formatter)

# Add handlers to the logger
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# =======================
# Global Variables
# =======================

root_directory = None
db = None  # Will be initialized in each process

# =======================
# Utility Functions
# =======================

def calculate_file_hash(file_path):
    """Calculate SHA256 hash of a file."""
    sha256_hash = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    except Exception as e:
        logger.error(f"Error calculating hash for {file_path}: {e}")
        return None

def is_file_ingested(db, file_path, file_hash):
    """Check if a file has already been ingested based on its path and hash."""
    if not file_hash:
        return False
    try:
        documents = db['documents']
        return documents.find_one({
            'file_path': file_path,
            'file_hash': file_hash
        }) is not None
    except Exception as e:
        logger.error(f"Error checking ingestion status for {file_path}: {e}")
        return False

def clean_json(json_text):
    """Remove control characters and extract valid JSON content."""
    # Remove control characters
    json_text = re.sub(r'[\x00-\x1F\x7F]', '', json_text)
    # Attempt to find the first and last curly braces
    start_index = json_text.find('{')
    end_index = json_text.rfind('}')
    if start_index != -1 and end_index != -1 and end_index > start_index:
        json_substring = json_text[start_index:end_index + 1]
        try:
            json.loads(json_substring)
            return json_substring
        except json.JSONDecodeError:
            # Try to fix common JSON issues
            try:
                fixed_json = json_substring.encode('utf-8').decode('unicode_escape', 'ignore')
                json.loads(fixed_json)
                return fixed_json
            except json.JSONDecodeError:
                raise ValueError("Invalid JSON format after cleaning.")
    raise ValueError("Invalid JSON format: Unable to find valid JSON object.")

def load_and_validate_json_file(file_path):
    """Load a JSON file, validate its content, and return it as a dictionary."""
    filename = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            json_content = file.read()
        cleaned_json_content = clean_json(json_content)
        json_data = json.loads(cleaned_json_content)
        json_data.setdefault('filename', filename)
        json_data.setdefault('relative_path', os.path.relpath(file_path, start=root_directory))
        json_data['file_path'] = file_path
        json_data['file_hash'] = calculate_file_hash(file_path)
        return json_data, None
    except json.JSONDecodeError as e:
        error_msg = f"Error decoding JSON in {filename}: {str(e)}"
        return None, error_msg
    except Exception as e:
        error_msg = f"Error processing file {filename}: {str(e)}"
        return None, error_msg

def collect_unique_terms(json_data):
    """Collect unique words and phrases from the JSON data."""
    unique_terms = {}
    for field, value in json_data.items():
        if isinstance(value, str):
            words = re.findall(r'\w+', value.lower())
            phrases = [' '.join(pair) for pair in zip(words, words[1:])]
            unique_terms.setdefault(field, {'words': Counter(), 'phrases': Counter()})
            unique_terms[field]['words'].update(words)
            unique_terms[field]['phrases'].update(phrases)
        elif isinstance(value, list):
            for item in value:
                if isinstance(item, str):
                    words = re.findall(r'\w+', item.lower())
                    phrases = [' '.join(pair) for pair in zip(words, words[1:])]
                    unique_terms.setdefault(field, {'words': Counter(), 'phrases': Counter()})
                    unique_terms[field]['words'].update(words)
                    unique_terms[field]['phrases'].update(phrases)
    return unique_terms

def merge_unique_terms(main_dict, new_dict):
    """Merge two unique terms dictionaries."""
    for field, terms in new_dict.items():
        if field not in main_dict:
            main_dict[field] = {'words': Counter(), 'phrases': Counter()}
        if not isinstance(terms.get('words'), Counter) or not isinstance(terms.get('phrases'), Counter):
            logger.error(f"Expected 'words' and 'phrases' to be Counters in field '{field}', got {type(terms.get('words'))} and {type(terms.get('phrases'))}.")
            continue
        main_dict[field]['words'].update(terms['words'])
        main_dict[field]['phrases'].update(terms['phrases'])

def save_unique_terms(db, unique_terms_dict):
    """Save the unique terms to the database in a flattened structure."""
    unique_terms_collection = db['unique_terms']
    unique_terms_documents = []
    for field, terms in unique_terms_dict.items():
        for word, count in terms['words'].items():
            if count >= 2:
                unique_terms_documents.append({
                    "term": word,
                    "field": field,
                    "count": count,
                    "type": "word"
                })
        for phrase, count in terms['phrases'].items():
            if count >= 2:
                unique_terms_documents.append({
                    "term": phrase,
                    "field": field,
                    "count": count,
                    "type": "phrase"
                })
    try:
        unique_terms_collection.delete_many({})
        if unique_terms_documents:
            unique_terms_collection.insert_many(unique_terms_documents)
            unique_terms_collection.create_index([("term", 1)])
            unique_terms_collection.create_index([("field", 1)])
            unique_terms_collection.create_index([("type", 1)])
        logger.info("Unique terms updated in the database.")
    except Exception as e:
        logger.error(f"Error saving unique terms: {e}")

# Optionally, save unique terms to a file for faster loading
import pickle

def save_unique_terms_to_file(unique_terms_dict, filename='unique_terms.pkl'):
    """Serialize and save unique terms to a file."""
    try:
        with open(filename, 'wb') as f:
            pickle.dump(unique_terms_dict, f)
        logger.info(f"Unique terms saved to file: {filename}")
    except Exception as e:
        logger.error(f"Error saving unique terms to file: {e}")

# =======================
# Processing Functions
# =======================

def init_db():
    """Initialize a new MongoDB connection for each process."""
    global db
    try:
        db = get_db()
    except Exception as e:
        logger.error(f"Failed to initialize database connection: {e}")
        raise e

def process_file(file_path):
    """Process a single file and return the result."""
    # Initialize database connection for this process
    if db is None:
        init_db()
    filename = os.path.basename(file_path)
    logger.debug(f"Processing file: {filename}")
    result = {'processed': [], 'failed': [], 'skipped': []}
    unique_terms = None

    try:
        file_hash = calculate_file_hash(file_path)
        if is_file_ingested(db, file_path, file_hash):
            logger.debug(f"File already ingested: {filename}")
            result['skipped'].append(file_path)
            return result, unique_terms

        json_data, error = load_and_validate_json_file(file_path)
        if json_data:
            try:
                update_field_structure(db, json_data)
                insert_document(db, json_data)
                logger.debug(f"Processed and inserted document: {filename}")
                result['processed'].append(file_path)
                unique_terms = collect_unique_terms(json_data)
            except Exception as e:
                error = f"Error processing {filename}: {str(e)}"
                logger.error(error)
                result['failed'].append((file_path, error))
        else:
            if error:
                logger.error(error)
                result['failed'].append((file_path, error))

    except Exception as e:
        error = f"Unexpected error processing {filename}: {str(e)}"
        logger.error(error)
        result['failed'].append((file_path, error))

    return result, unique_terms

def get_all_files(directory):
    """Recursively get all JSON and TXT files in the given directory and its subdirectories."""
    file_list = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.json', '.txt')):
                file_list.append(os.path.join(root, file))
    return file_list

def process_directory(directory_path):
    """Process all files in a directory and its subdirectories using multiprocessing."""
    global root_directory
    root_directory = directory_path

    start_time = time.time()
    files = get_all_files(directory_path)
    total = len(files)
    final_unique = {}

    logger.info(f"Found {total} files to process.")

    batch_size = 1000  # Adjust based on system capabilities
    num_batches = (total // batch_size) + (1 if total % batch_size != 0 else 0)

    # Initialize results_dict in the main process
    results_dict = {
        'processed': [],
        'failed': [],
        'skipped': []
    }

    with tqdm(total=total, desc="Processing files") as pbar:
        for batch_num in range(num_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, total)
            batch_files = files[start_idx:end_idx]
            logger.info(f"Processing batch {batch_num + 1}/{num_batches} with {len(batch_files)} files.")

            with Pool(processes=min(cpu_count(), 8), initializer=init_db) as pool:
                for res in pool.imap_unordered(process_file, batch_files):
                    if not isinstance(res, tuple) or len(res) != 2:
                        logger.error(f"Unexpected result format: {res}")
                        continue
                    result, unique_terms = res
                    for key in ['processed', 'failed', 'skipped']:
                        if not isinstance(result[key], list):
                            logger.error(f"Expected result[{key}] to be a list, got {type(result[key])} instead.")
                            continue
                        results_dict[key].extend(result[key])
                    if unique_terms:
                        merge_unique_terms(final_unique, unique_terms)
                    pbar.update(1)

    # Initialize database connection to save unique terms
    if db is None:
        init_db()
    save_unique_terms(db, final_unique)
    save_unique_terms_to_file(final_unique)

    logger.info("\nProcessing Summary:")
    logger.info(f"Total files found: {total}")
    logger.info(f"Successfully processed: {len(results_dict['processed'])}")
    logger.info(f"Skipped (already ingested): {len(results_dict['skipped'])}")
    logger.info(f"Failed to process: {len(results_dict['failed'])}")

    if results_dict['failed']:
        logger.info("\nFailed files:")
        for file_path, error in results_dict['failed']:
            logger.error(f"- {file_path}: {error}")

    duration = time.time() - start_time
    logger.info(f"\nTotal processing time: {duration:.2f} seconds.")

# =======================
# Main Execution
# =======================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Process and validate JSON and TXT files for the railroad documents database.")
    parser.add_argument("data_directory", nargs='?', default='archives',
                        help="Path to the root directory containing JSON and/or text files to process (default: './archives')")
    args = parser.parse_args()

    # Get the absolute path of the script's directory
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # Construct the data directory path
    data_directory = os.path.abspath(os.path.join(script_dir, args.data_directory))

    if not os.path.exists(data_directory):
        logger.error(f"Error: The specified directory does not exist: {data_directory}")
        logger.info(f"Creating directory: {data_directory}")
        try:
            os.makedirs(data_directory)
            logger.info(f"Directory created successfully: {data_directory}")
        except Exception as e:
            logger.error(f"Failed to create directory: {e}")
            exit(1)

    logger.info(f"Processing directory: {data_directory}")
    print("Don't Forget To Turn On Your Fan!")
    process_directory(data_directory)


********************************************************************************

File: app/database_setup.py
********************************************************************************

from pymongo import MongoClient
from bson import ObjectId
import logging

# =======================
# Logging Configuration
# =======================
logger = logging.getLogger('DatabaseSetupLogger')
logger.setLevel(logging.INFO)

# Create handlers
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
file_handler = logging.FileHandler('database_setup.log')
file_handler.setLevel(logging.DEBUG)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
file_handler.setFormatter(formatter)

logger.addHandler(console_handler)
logger.addHandler(file_handler)

# =======================
# Database Functions
# =======================

def get_client():
    """Initialize and return a new MongoDB client."""
    try:
        client = MongoClient('mongodb://admin:secret@localhost:27017', serverSelectionTimeoutMS=1000)
        logger.info("Successfully connected to MongoDB.")
        return client
    except Exception as e:
        logger.error(f"Failed to connect to MongoDB: {e}")
        raise e

def get_db(client):
    """Return the database instance."""
    return client['railroad_documents']

def get_collections(db):
    """Return the collections used in the application."""
    documents = db['documents']
    unique_terms_collection = db['unique_terms']
    field_structure_collection = db['field_structure']
    logger.info("Accessed collections from the database.")
    return documents, unique_terms_collection, field_structure_collection

def insert_document(client, document):
    """Insert a document into the 'documents' collection."""
    db = get_db(client)
    try:
        documents = db['documents']
        documents.insert_one(document)
        logger.info("Inserted document into 'documents' collection.")
    except Exception as e:
        logger.error(f"Error inserting document: {e}")
        raise e

def update_document(client, document_id, update_data):
    """
    Update a document's information.
    :param client: MongoDB client
    :param document_id: The ObjectId of the document to update
    :param update_data: A dictionary containing the fields to update
    :return: The result of the update operation
    """
    db = get_db(client)
    documents = db['documents']
    result = documents.update_one({"_id": ObjectId(document_id)}, {"$set": update_data})
    return result.modified_count

def delete_document(client, document_id):
    """
    Delete a document from the database.
    :param client: MongoDB client
    :param document_id: The ObjectId of the document to delete
    :return: The result of the delete operation
    """
    db = get_db(client)
    documents = db['documents']
    result = documents.delete_one({"_id": ObjectId(document_id)})
    return result.deleted_count

def update_field_structure(client, json_data):
    """Update the field structure in the 'field_structure' collection based on json_data."""
    db = get_db(client)
    try:
        field_structure = db['field_structure']

        def flatten_json(y):
            out = {}
            def flatten(x, name=''):
                if isinstance(x, dict):
                    for a in x:
                        flatten(x[a], f'{name}{a}.')
                elif isinstance(x, list):
                    i = 0
                    for a in x:
                        flatten(a, f'{name}{i}.')
                        i += 1
                else:
                    out[name[:-1]] = type(x).__name__
            flatten(y)
            return out

        flat_json = flatten_json(json_data)

        for field, field_type in flat_json.items():
            field_structure.update_one(
                {'field': field},
                {'$addToSet': {'types': field_type}},
                upsert=True
            )
        logger.info("Updated field structure based on JSON data.")
    except Exception as e:
        logger.error(f"Error updating field structure: {e}")
        raise e

def is_file_ingested(client, file_path, file_hash):
    """Check if a file has already been ingested based on its path and hash."""
    if not file_hash:
        return False
    db = get_db(client)
    try:
        documents = db['documents']
        ingested = documents.find_one({
            'file_path': file_path,
            'file_hash': file_hash
        }) is not None
        logger.debug(f"File ingestion check for {file_path}: {ingested}")
        return ingested
    except Exception as e:
        logger.error(f"Error checking ingestion status for {file_path}: {e}")
        return False

def save_unique_terms(client, unique_terms_dict):
    """Save the unique terms to the database in a flattened structure."""
    db = get_db(client)
    unique_terms_collection = db['unique_terms']
    unique_terms_documents = []
    
    for field, terms in unique_terms_dict.items():
        for word, count in terms['words'].items():
            if count >= 2:
                unique_terms_documents.append({
                    "term": word,
                    "field": field,
                    "count": count,
                    "type": "word"
                })
        for phrase, count in terms['phrases'].items():
            if count >= 2:
                unique_terms_documents.append({
                    "term": phrase,
                    "field": field,
                    "count": count,
                    "type": "phrase"
                })

    try:
        unique_terms_collection.delete_many({})
        if unique_terms_documents:
            unique_terms_collection.insert_many(unique_terms_documents)
            unique_terms_collection.create_index([("term", 1)])
            unique_terms_collection.create_index([("field", 1)])
            unique_terms_collection.create_index([("type", 1)])
        logger.info("Saved unique terms to the database.")
    except Exception as e:
        logger.error(f"Error saving unique terms: {e}")

def find_document_by_id(client, document_id):
    """
    Find a document by its ObjectId.
    :param client: MongoDB client
    :param document_id: The ObjectId of the document
    :return: The document, or None if not found
    """
    db = get_db(client)
    documents = db['documents']
    try:
        return documents.find_one({"_id": ObjectId(document_id)})
    except Exception as e:
        logger.error(f"Error finding document by ID: {e}")
        return None

def get_field_structure(client):
    """
    Get the current field structure.
    :param client: MongoDB client
    :return: The current field structure
    """
    db = get_db(client)
    field_structure_collection = db['field_structure']
    structure = field_structure_collection.find_one({"_id": "current_structure"})
    return structure['structure'] if structure else {}


# =======================
# Main Execution (Optional)
# =======================
if __name__ == "__main__":
    client = get_client()  # Get the MongoDB client
    db = get_db(client)    # Get the database
    documents, unique_terms_collection, field_structure_collection = get_collections(db)
    logger.info("Database setup module executed directly.")


********************************************************************************

File: app/json_validator_multi.py
********************************************************************************

import os
import json
import re
import multiprocessing
from tqdm import tqdm

def clean_json(json_text):
    """
    Cleans the JSON text by removing control characters and extracting the valid JSON portion.
    """
    # Remove all control characters
    json_text = re.sub(r'[\x00-\x1F\x7F]', '', json_text)

    # Find the index of the first '{' and the last '}'
    start_index = json_text.find('{')
    end_index = json_text.rfind('}')

    # Extract the clean JSON string
    if start_index != -1 and end_index != -1:
        clean_json_text = json_text[start_index:end_index + 1]
        return clean_json_text
    else:
        raise ValueError("Invalid JSON format: Unable to find '{' or '}'.")

def validate_json_file(file_path):
    """
    Validates and cleans a single JSON file.
    Converts valid .txt files to .json and renames invalid ones to .bad.
    """
    filename = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            json_content = file.read()

        # Clean the JSON content before validation
        cleaned_json_content = clean_json(json_content)
        cleaned = cleaned_json_content != json_content

        # Validate the cleaned JSON content
        json_data = json.loads(cleaned_json_content)

        # Define the new file path with .json extension
        base_name, _ = os.path.splitext(file_path)
        new_file_path = f"{base_name}.json"

        # Write the validated and cleaned JSON to the new file
        with open(new_file_path, 'w', encoding='utf-8') as file:
            json.dump(json_data, file, indent=4)

        # Remove the original .txt file
        os.remove(file_path)

        return (filename, True, cleaned)
    except Exception as e:
        # Rename the original .txt file by appending .bad
        bad_file_path = f"{file_path}.bad"
        try:
            os.rename(file_path, bad_file_path)
        except Exception as rename_error:
            return (filename, False, f"Failed to rename to .bad. Original error: {e}; Rename error: {rename_error}")
        return (filename, False, f"File renamed to .bad due to invalid JSON. Error: {e}")

def validate_and_replace_json_files(source_dir, num_workers):
    """
    Traverses the source directory recursively to find and process all .txt files.
    Utilizes multiprocessing for parallel processing.
    """
    # Collect all .txt file paths recursively
    file_paths = []
    print(f"ðŸ” Starting to walk through the source directory: {source_dir}\n")
    for root, dirs, files in os.walk(source_dir, followlinks=True):
        print(f"ðŸ“‚ Accessing directory: {root}")
        for f in files:
            if f.lower().endswith('.txt'):
                full_path = os.path.join(root, f)
                file_paths.append(full_path)
                print(f"ðŸ“„ Found .txt file: {full_path}")
    total_files = len(file_paths)

    print(f"\nðŸ“Š Processing {total_files} .txt files with {num_workers} worker processes...\n")

    # Initialize counters
    cleaned_count = 0
    replaced_count = 0
    invalid_count = 0

    if total_files == 0:
        print("ðŸš« No .txt files found. Exiting the script.")
        return

    # Use multiprocessing Pool to process files in parallel
    with multiprocessing.Pool(num_workers) as pool:
        results = []
        for result in tqdm(pool.imap_unordered(validate_json_file, file_paths), total=total_files, desc="Validating JSON files"):
            results.append(result)

    # Process the results
    for filename, is_valid, info in results:
        if is_valid:
            if info:
                cleaned_count += 1
            replaced_count += 1
        else:
            invalid_count += 1

    print(f"\nâœ… Processing complete:")
    print(f"âœ”ï¸  Valid JSON files replaced with .json: {replaced_count}")
    print(f"ðŸ§¹ Files cleaned: {cleaned_count}")
    print(f"âŒ Invalid or unreadable files renamed to .bad: {invalid_count}")

    print("\nðŸ“‹ Detailed results:")
    for filename, is_valid, info in results:
        if is_valid:
            if info:
                print(f"âœ… {filename} was cleaned and replaced with a .json file.")
            else:
                print(f"âœ… {filename} is valid and replaced with a .json file.")
        else:
            print(f"âŒ {filename} was invalid and renamed to .bad. Error: {info}")

if __name__ == "__main__":
    # Specify the source directory
    source_directory = "/home/lhyman/coding/nosql_reader/archives"

    # Calculate the number of worker processes (3/4 of available CPUs)
    num_cpus = multiprocessing.cpu_count()
    num_workers = max(1, int(num_cpus * 0.75))

    # Start the validation and replacement process
    validate_and_replace_json_files(source_directory, num_workers)


********************************************************************************

File: app/json_validator.py
********************************************************************************

import os
import json
import re
import multiprocessing
from tqdm import tqdm

def clean_json(json_text):
    # Remove all control characters
    json_text = re.sub(r'[\x00-\x1F\x7F]', '', json_text)

    # Find the index of the first '{' and the last '}'
    start_index = json_text.find('{')
    end_index = json_text.rfind('}')

    # Extract the clean JSON string
    if start_index != -1 and end_index != -1:
        clean_json_text = json_text[start_index:end_index + 1]
        return clean_json_text
    else:
        raise ValueError("Invalid JSON format: Unable to find '{' or '}'.")

def validate_json_file(file_path):
    filename = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            json_content = file.read()

        # Clean the JSON content before validation
        cleaned_json_content = clean_json(json_content)
        cleaned = cleaned_json_content != json_content

        # Validate the cleaned JSON content
        json_data = json.loads(cleaned_json_content)

        # Define the new file path with .json extension
        base_name, _ = os.path.splitext(file_path)
        new_file_path = f"{base_name}.json"

        # Write the validated and cleaned JSON to the new file
        with open(new_file_path, 'w', encoding='utf-8') as file:
            json.dump(json_data, file, indent=4)

        # Remove the original .txt file
        os.remove(file_path)

        return (filename, True, cleaned)
    except Exception as e:
        return (filename, False, str(e))

def validate_and_replace_json_files(source_dir, num_workers):
    # Collect all .txt file paths recursively
    file_paths = []
    for root, dirs, files in os.walk(source_dir):
        for f in files:
            if f.lower().endswith('.txt'):
                file_paths.append(os.path.join(root, f))
    total_files = len(file_paths)

    print(f"Processing {total_files} .txt files with {num_workers} worker processes...")

    # Initialize counters
    cleaned_count = 0
    replaced_count = 0
    invalid_count = 0

    # Use multiprocessing Pool to process files in parallel
    with multiprocessing.Pool(num_workers) as pool:
        # Use imap_unordered for better performance and integrate with tqdm
        results = []
        for result in tqdm(pool.imap_unordered(validate_json_file, file_paths), total=total_files, desc="Validating JSON files"):
            results.append(result)

    # Process the results
    for filename, is_valid, info in results:
        if is_valid:
            if info:
                cleaned_count += 1
            replaced_count += 1
        else:
            invalid_count += 1

    print(f"\nProcessing complete:")
    print(f"Valid JSON files replaced with .json: {replaced_count}")
    print(f"Files cleaned: {cleaned_count}")
    print(f"Invalid or unreadable files remain as .txt: {invalid_count}")

    print("\nDetailed results:")
    for filename, is_valid, info in results:
        if is_valid:
            if info:
                print(f"{filename} was cleaned and replaced with a .json file.")
            else:
                print(f"{filename} is valid and replaced with a .json file.")
        else:
            print(f"{filename} is invalid or unreadable. Remains as .txt. Error: {info}")

if __name__ == "__main__":
    # Specify the source directory
    source_directory = r"G:\My Drive\2024-2025\coding\rolls_txt"

    # Calculate the number of worker processes (3/4 of available CPUs)
    num_cpus = multiprocessing.cpu_count()
    num_workers = max(1, int(num_cpus * 0.75))

    # Start the validation and replacement process
    validate_and_replace_json_files(source_directory, num_workers)


********************************************************************************

File: app/routes.py
********************************************************************************

from flask import request, jsonify, render_template, redirect, url_for, flash, session, abort, Response, send_file, send_from_directory
from functools import wraps
from app import app, cache
from database_setup import (
    get_client,
    get_db,
    get_collections,
    insert_document,
    update_document,
    delete_document,
    get_field_structure,
    find_document_by_id,
    update_field_structure,
    save_unique_terms
)
from bson import ObjectId
from werkzeug.security import generate_password_hash, check_password_hash
import math
import json
import re
import logging
import time
from datetime import datetime, timedelta
import random
import csv
from io import StringIO
import os
import uuid
from urllib.parse import unquote

app.logger.setLevel(logging.DEBUG)

# Hashed password (generate this using generate_password_hash('your_actual_password'))
ADMIN_PASSWORD_HASH = 'pbkdf2:sha256:260000$uxZ1Fkjt9WQCHwuN$ca37dfb41ebc26b19daf24885ebcd09f607cab85f92dcab13625627fd9ee902a'

# Login attempt tracking
MAX_ATTEMPTS = 5
LOCKOUT_TIME = 15 * 60  # 15 minutes in seconds
login_attempts = {}

def is_locked_out(ip):
    if ip in login_attempts:
        attempts, last_attempt_time = login_attempts[ip]
        if attempts >= MAX_ATTEMPTS:
            if datetime.now() - last_attempt_time < timedelta(seconds=LOCKOUT_TIME):
                return True
            else:
                login_attempts[ip] = (0, datetime.now())
    return False

def update_login_attempts(ip, success):
    if ip in login_attempts:
        attempts, _ = login_attempts[ip]
        if success:
            login_attempts[ip] = (0, datetime.now())
        else:
            login_attempts[ip] = (attempts + 1, datetime.now())
    else:
        login_attempts[ip] = (0, datetime.now()) if success else (1, datetime.now())

# Login required decorator
def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'logged_in' not in session:
            return redirect(url_for('login', next=request.url))
        return f(*args, **kwargs)
    return decorated_function

@app.route('/')
# @login_required
def index():
    app.logger.info('Handling request to index')
    num_search_fields = 3  # Number of search fields to display
    client = get_client()
    field_structure = get_field_structure(client)
    return render_template('index.html', num_search_fields=num_search_fields, field_structure=field_structure)

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        ip = request.remote_addr

        if is_locked_out(ip):
            flash('Too many failed attempts. Please try again later.')
            return render_template('login.html')

        # Verify CAPTCHA
        user_captcha = request.form.get('captcha')
        correct_captcha = request.form.get('captcha_answer')
        if user_captcha != correct_captcha:
            flash('Incorrect CAPTCHA')
            return redirect(url_for('login'))

        if check_password_hash(ADMIN_PASSWORD_HASH, request.form['password']):
            session['logged_in'] = True
            update_login_attempts(ip, success=True)
            flash('You were successfully logged in')
            next_page = request.args.get('next')
            return redirect(next_page or url_for('index'))
        else:
            update_login_attempts(ip, success=False)
            time.sleep(2)  # Add a delay after failed attempt
            flash('Invalid password')

    # Generate CAPTCHA for GET requests
    captcha_num1 = random.randint(1, 10)
    captcha_num2 = random.randint(1, 10)
    captcha_answer = str(captcha_num1 + captcha_num2)

    return render_template('login.html', captcha_num1=captcha_num1, captcha_num2=captcha_num2, captcha_answer=captcha_answer)

@app.route('/logout')
def logout():
    session.pop('logged_in', None)
    flash('You were logged out')
    return redirect(url_for('index'))

@app.route('/search', methods=['POST'])
# @login_required
def search():
    try:
        data = request.get_json()
        app.logger.debug(f"Received search request: {data}")

        page = int(data.get('page', 1))
        per_page = int(data.get('per_page', 50))

        query = build_query(data)
        app.logger.debug(f"Constructed MongoDB query: {query}")

        client = get_client()
        db = get_db(client)
        documents, _, _ = get_collections(db)
        total_count = documents.count_documents(query)
        search_results = list(documents.find(query).skip((page - 1) * per_page).limit(per_page))

        for doc in search_results:
            doc['_id'] = str(doc['_id'])

        total_pages = math.ceil(total_count / per_page) if per_page else 1

        # Generate unique search ID
        search_id = str(uuid.uuid4())
        # Store the ordered list of document IDs
        ordered_ids = [doc['_id'] for doc in search_results]
        cache.set(f'search_{search_id}', ordered_ids, timeout=3600)  # Expires in 1 hour

        app.logger.debug(f"Search ID: {search_id}, Found {total_count} documents.")

        return jsonify({
            "search_id": search_id,
            "documents": search_results,
            "total_count": total_count,
            "current_page": page,
            "total_pages": total_pages,
            "per_page": per_page
        })

    except Exception as e:
        app.logger.error(f"An error occurred during search: {str(e)}", exc_info=True)
        return jsonify({"error": "An internal error occurred"}), 500

def build_query(data):
    query = {}
    criteria_list = []

    app.logger.debug(f"Building query from search data: {data}")

    for i in range(1, 4):
        field = data.get(f'field{i}')
        search_term = data.get(f'searchTerm{i}')
        operator = data.get(f'operator{i}')

        if field and search_term:
            condition = {}
            if operator == 'NOT':
                condition[field] = {'$not': {'$regex': re.escape(search_term), '$options': 'i'}}
            else:
                condition[field] = {'$regex': re.escape(search_term), '$options': 'i'}
            
            criteria_list.append((operator, condition))
            app.logger.debug(f"Processed field {field} with search term '{search_term}' and operator '{operator}'")

    if criteria_list:
        and_conditions = []
        or_conditions = []

        for operator, condition in criteria_list:
            if operator == 'AND' or operator == 'NOT':
                and_conditions.append(condition)
            elif operator == 'OR':
                or_conditions.append(condition)

        if and_conditions:
            query['$and'] = and_conditions

        if or_conditions:
            if '$or' not in query:
                query['$or'] = or_conditions
            else:
                query['$or'].extend(or_conditions)

    app.logger.debug(f"Final query: {query}")
    return query



@app.route('/document/<string:doc_id>')
def document_detail(doc_id):
    # Hard-coded SHOW_EMPTY variable
    SHOW_EMPTY = False  # Set to True to show empty fields, False to hide them

    # Function to clean the document data
    def clean_data(data):
        empty_values = [None, '', 'N/A', 'null', [], {}, 'None']
        if isinstance(data, dict):
            return {
                k: clean_data(v)
                for k, v in data.items()
                if v not in empty_values and clean_data(v) not in empty_values
            }
        elif isinstance(data, list):
            return [
                clean_data(item)
                for item in data
                if item not in empty_values and clean_data(item) not in empty_values
            ]
        else:
            return data

    search_id = request.args.get('search_id')
    if not search_id:
        flash('Missing search context.')
        return redirect(url_for('index'))

    try:
        client = get_client()
        document = find_document_by_id(client, doc_id)
        if not document:
            abort(404, description="Document not found.")

        # Decide whether to clean the document based on SHOW_EMPTY
        if SHOW_EMPTY:
            cleaned_document = document
        else:
            # Clean the document to remove empty fields
            cleaned_document = clean_data(document)
        cleaned_document['_id'] = str(cleaned_document.get('_id', ''))

        # Retrieve the ordered list from cache
        ordered_ids = cache.get(f'search_{search_id}')
        if not ordered_ids:
            flash('Search context expired. Please perform the search again.')
            return redirect(url_for('index'))

        try:
            current_index = ordered_ids.index(doc_id)
        except ValueError:
            flash('Document not found in the current search results.')
            return redirect(url_for('index'))

        # Determine previous and next IDs based on the search order
        prev_id = ordered_ids[current_index - 1] if current_index > 0 else None
        next_id = ordered_ids[current_index + 1] if current_index < len(ordered_ids) - 1 else None

        # Use the relative_path field from the cleaned document
        relative_path = cleaned_document.get('relative_path', '')
        if relative_path.endswith('.json'):
            image_path = relative_path[:-5]  # Removes the '.json' extension
        else:
            image_path = relative_path

        # Adjust the image path if necessary
        absolute_image_path = os.path.join(app.root_path, 'archives', image_path)
        image_exists = os.path.isfile(absolute_image_path)

        app.logger.debug(f"Image path: {image_path}")
        app.logger.debug(f"Absolute image path: {absolute_image_path}")

        return render_template(
            'document-detail.html',
            document=cleaned_document,
            prev_id=prev_id,
            next_id=next_id,
            search_id=search_id,
            image_exists=image_exists,
            image_path=image_path,
            absolute_image_path=absolute_image_path  # Pass this for debugging
        )
    except Exception as e:
        app.logger.error(f"Error in document_detail: {str(e)}")
        abort(500)




@app.route('/images/<path:filename>')
# @login_required
def serve_image(filename):
    # Decode the filename to handle spaces and special characters
    filename = unquote(filename)
    data_dir = os.path.join(app.root_path, 'archives')
    full_path = os.path.join(data_dir, filename)

    if os.path.isfile(full_path):
        # Determine the directory and file for send_from_directory
        directory, file = os.path.split(full_path)
        return send_from_directory(directory, file)
    else:
        app.logger.error(f"Image not found: {full_path}")
        abort(404)

@app.route('/search-terms', methods=['GET'])
# @login_required
def search_terms():
    if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
        # Handle AJAX request
        field = request.args.get('field')
        app.logger.debug(f"AJAX request for field: {field}")
        if not field:
            return jsonify({"error": "No field specified"}), 400

        client = get_client()
        db = get_db(client)
        documents, unique_terms_collection, _ = get_collections(db)
        # Fetch unique terms for the specified field from unique_terms_collection
        unique_terms_doc = unique_terms_collection.find_one({"field": field})
        if not unique_terms_doc:
            app.logger.debug(f"No terms found for field '{field}'.")
            return jsonify({
                "words": [],
                "phrases": [],
                "unique_words": 0,
                "unique_phrases": 0,
                "total_records": documents.count_documents({}),
                "message": f"No terms found for field '{field}'."
            }), 200  # Changed status to 200

        words = unique_terms_doc.get('words', {})
        phrases = unique_terms_doc.get('phrases', {})
        unique_words_count = len(words)
        unique_phrases_count = len(phrases)
        total_records = documents.count_documents({})

        # Convert words and phrases to lists of dictionaries
        words_list = [{'word': word, 'count': count} for word, count in sorted(words.items())]
        phrases_list = [{'phrase': phrase, 'count': count} for phrase, count in sorted(phrases.items())]

        data = {
            'words': words_list,
            'phrases': phrases_list,
            'unique_words': unique_words_count,
            'unique_phrases': unique_phrases_count,
            'total_records': total_records
        }

        return jsonify(data)
    else:
        client = get_client()
        field_structure = get_field_structure(client)
        return render_template('search-terms.html', field_structure=field_structure)

@app.route('/database-info')
# @login_required
def database_info():
    client = get_client()
    db = get_db(client)
    field_structure = get_field_structure(client)
    documents, _, _ = get_collections(db)
    collection_info = []

    def count_documents_with_field(field_path):
        count = documents.count_documents({field_path: {'$exists': True}})
        return count

    def traverse_structure(structure, current_path=''):
        for field, value in structure.items():
            path = f"{current_path}.{field}" if current_path else field
            if isinstance(value, dict):
                traverse_structure(value, current_path=path)
            else:
                count = count_documents_with_field(path)
                collection_info.append({
                    'name': path,
                    'count': count
                })

    traverse_structure(field_structure)

    return render_template('database-info.html', collection_info=collection_info)

@app.route('/settings', methods=['GET', 'POST'])
# @login_required
def settings():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')

    if request.method == 'POST':
        new_config = request.form.to_dict()

        for key in ['fonts', 'sizes', 'colors', 'spacing']:
            if key in new_config:
                try:
                    new_config[key] = json.loads(new_config[key])
                except json.JSONDecodeError:
                    flash(f"Invalid JSON format for {key}.", 'danger')
                    return redirect(url_for('settings'))

        try:
            with open(config_path, 'w') as config_file:
                json.dump(new_config, config_file, indent=4)
            app.config['UI_CONFIG'] = new_config
            flash('Settings updated successfully', 'success')
        except Exception as e:
            app.logger.error(f"Error updating settings: {str(e)}")
            flash('Failed to update settings.', 'danger')
        return redirect(url_for('settings'))

    try:
        if os.path.exists(config_path):
            with open(config_path) as config_file:
                config = json.load(config_file)
        else:
            config = {}
    except json.JSONDecodeError:
        config = {}
        flash('Configuration file is corrupted. Using default settings.', 'warning')

    return render_template('settings.html', config=config)

# Consider streaming if it ends up being thousands of documents
@app.route('/export_selected_csv', methods=['POST'])
# @login_required
def export_selected_csv():
    try:
        data = request.get_json()
        document_ids = data.get('document_ids', [])
        if not document_ids:
            return jsonify({"error": "No document IDs provided"}), 400

        # Convert string IDs to ObjectIds, handle invalid IDs
        valid_ids = []
        for doc_id in document_ids:
            try:
                valid_ids.append(ObjectId(doc_id))
            except Exception as e:
                app.logger.warning(f"Invalid document ID: {doc_id}")

        if not valid_ids:
            return jsonify({"error": "No valid document IDs provided"}), 400

        client = get_client()
        db = get_db(client)
        documents, _, _ = get_collections(db)
        # Check if any documents exist with the provided IDs
        count = documents.count_documents({"_id": {"$in": valid_ids}})
        if count == 0:
            return jsonify({"error": "No documents found for the provided IDs."}), 404

        # Retrieve the documents
        documents_cursor = documents.find({"_id": {"$in": valid_ids}})

        # Create CSV
        output = StringIO()
        writer = csv.writer(output)
        writer.writerow(['filename', 'OCR', 'original_json'])  # Header row

        for doc in documents_cursor:
            filename = doc.get('filename', 'N/A')
            ocr = doc.get('summary', 'N/A')  # Adjust field as necessary
            original_json = json.dumps(doc, default=str)  # Convert ObjectId to string if necessary
            writer.writerow([filename, ocr, original_json])

        # Prepare CSV for download
        output.seek(0)
        return Response(
            output.getvalue(),
            mimetype='text/csv',
            headers={'Content-Disposition': 'attachment; filename=selected_documents.csv'}
        )

    except Exception as e:
        app.logger.error(f"Error exporting selected CSV: {str(e)}", exc_info=True)
        return jsonify({"error": "An internal error occurred"}), 500

@app.errorhandler(404)
def not_found_error(error):
    return render_template('error.html', message='Page not found'), 404

@app.errorhandler(500)
def internal_error(error):
    return render_template('error.html', message='An unexpected error has occurred'), 500


********************************************************************************

File: app/read_pickle.py
********************************************************************************

import pickle

# Specify the filename
filename = 'unique_terms.pkl'

try:
    # Load the contents of the .pkl file
    with open(filename, 'rb') as f:
        unique_terms = pickle.load(f)
    
    # Display the contents
    print("Contents of unique_terms.pkl:")
    for field, terms in unique_terms.items():
        print(f"\nField: {field}")
        print("Words:")
        for word, count in terms['words'].items():
            print(f"  {word}: {count}")
        print("Phrases:")
        for phrase, count in terms['phrases'].items():
            print(f"  {phrase}: {count}")

except Exception as e:
    print(f"Error loading {filename}: {e}")


********************************************************************************

File: app/templates/search-terms.html
********************************************************************************

<!-- File: templates/search-terms.html -->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Search Terms</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <!-- Include DataTables CSS -->
    <link rel="stylesheet" href="https://cdn.datatables.net/1.10.21/css/jquery.dataTables.css">
    <style>
        #loadingIndicator {
            display: none;
            text-align: center;
            margin-top: 20px;
        }
        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        nav ul {
            list-style-type: none;
            padding: 0;
            display: flex;
            gap: 15px;
        }
        nav ul li {
            display: inline;
        }
        nav ul li a {
            text-decoration: none;
            color: #3498db;
            font-weight: bold;
        }
        nav ul li a:hover {
            text-decoration: underline;
        }
        .section {
            margin-top: 30px;
        }
        #noDataMessage {
            display: none;
            color: red;
            margin-top: 20px;
            font-weight: bold;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Search Terms</h1>
        <nav>
            <ul>
                <li><a href="{{ url_for('index') }}">Home</a></li>
                <li><a href="{{ url_for('search_terms') }}">Search Terms</a></li>
                <li><a href="{{ url_for('database_info') }}">Database Info</a></li>
                <li><a href="{{ url_for('settings') }}">Settings</a></li>
            </ul>
        </nav>
        <div style="margin-top: 20px;">
            <label for="fieldSelect">Select Field:</label>
            <select id="fieldSelect">
                <option value="" disabled selected>Select a field</option>
                {% for field in field_structure|dictsort %}
                    {% if field[0] not in unique_fields %}
                        <option value="{{ field[0] }}">{{ field[0] }}</option>
                    {% endif %}
                {% endfor %}
            </select>
        </div>
        <div id="tableInfo" style="margin-top: 10px;">
            <p>Number of unique words: <span id="uniqueWords">0</span></p>
            <p>Number of unique phrases: <span id="uniquePhrases">0</span></p>
            <p>Total number of records: <span id="totalRecords">0</span></p>
        </div>
        <div id="loadingIndicator">
            <div class="spinner"></div>
            <p>Loading data...</p>
        </div>
        <!-- No Data Message -->
        <div id="noDataMessage"></div>
        <div class="section">
            <h2>Words</h2>
            <table id="wordsTable" class="display" style="width:100%; margin-top: 10px;">
                <thead>
                    <tr>
                        <th>Word</th>
                        <th>Count</th>
                    </tr>
                </thead>
                <tbody>
                    <!-- Initially empty; populated via AJAX -->
                </tbody>
            </table>
        </div>
        <div class="section">
            <h2>Phrases</h2>
            <table id="phrasesTable" class="display" style="width:100%; margin-top: 10px;">
                <thead>
                    <tr>
                        <th>Phrase</th>
                        <th>Count</th>
                    </tr>
                </thead>
                <tbody>
                    <!-- Initially empty; populated via AJAX -->
                </tbody>
            </table>
        </div>
    </div>
    <!-- Include jQuery and DataTables JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdn.datatables.net/1.10.21/js/jquery.dataTables.js"></script>
    <script>
        $(document).ready(function() {
            var wordsTable = $('#wordsTable').DataTable({
                "pageLength": 25,
                "order": [[ 0, "asc" ]],
                "columns": [
                    { "data": "word" },
                    { "data": "count" }
                ]
            });

            var phrasesTable = $('#phrasesTable').DataTable({
                "pageLength": 25,
                "order": [[ 0, "asc" ]],
                "columns": [
                    { "data": "phrase" },
                    { "data": "count" }
                ]
            });

            function updateTableInfo(data) {
                $('#uniqueWords').text(data.unique_words);
                $('#uniquePhrases').text(data.unique_phrases);
                $('#totalRecords').text(data.total_records);
            }

            $('#fieldSelect').on('change', function() {
                var selectedField = $(this).val();
                if (!selectedField) {
                    wordsTable.clear().draw();
                    phrasesTable.clear().draw();
                    updateTableInfo({ unique_words: 0, unique_phrases: 0, total_records: 0 });
                    $('#noDataMessage').hide();
                    return;
                }

                $('#loadingIndicator').show();
                $('#noDataMessage').hide();
                $('#wordsTableContainer').show();
                $('#phrasesTableContainer').show();

                $.ajax({
                    url: '/search-terms',
                    data: { field: selectedField },
                    success: function(data) {
                        // Check if both words and phrases are empty
                        if (data.words.length === 0 && data.phrases.length === 0) {
                            // Hide the tables
                            $('.section').hide();
                            // Show the no data message
                            $('#noDataMessage').text(data.message || 'No data available for this field.').show();
                        } else {
                            // Show the tables in case they were hidden
                            $('.section').show();
                            // Hide the no data message
                            $('#noDataMessage').hide();

                            // Populate words table
                            wordsTable.clear();
                            data.words.forEach(function(word) {
                                wordsTable.row.add({ word: word.word, count: word.count });
                            });
                            wordsTable.draw();

                            // Populate phrases table
                            phrasesTable.clear();
                            data.phrases.forEach(function(phrase) {
                                phrasesTable.row.add({ phrase: phrase.phrase, count: phrase.count });
                            });
                            phrasesTable.draw();
                        }

                        // Update table info
                        updateTableInfo(data);
                        $('#loadingIndicator').hide();
                    },
                    error: function() {
                        alert('Error fetching data. Please try again.');
                        $('#loadingIndicator').hide();
                    }
                });
            });
        });
    </script>
</body>
</html>


********************************************************************************

File: app/templates/login.html
********************************************************************************

<!-- File: templates/login.html -->
<!-- Created: 2024-08-12 11:00 -->

{% extends "base.html" %}

{% block content %}
    <h1>Login</h1>
    
    {% with messages = get_flashed_messages() %}
        {% if messages %}
            <ul class="flashes">
                {% for message in messages %}
                    <li>{{ message }}</li>
                {% endfor %}
            </ul>
        {% endif %}
    {% endwith %}
    
    <form method="post">
        <label for="password">Password:</label>
        <input type="password" id="password" name="password" required>
        <br><br>
        
        <label for="captcha">CAPTCHA: What is {{ captcha_num1 }} + {{ captcha_num2 }}?</label>
        <input type="number" id="captcha" name="captcha" required>
        <input type="hidden" name="captcha_answer" value="{{ captcha_answer }}">
        <br><br>
        
        <input type="submit" value="Login">
    </form>
{% endblock %}

********************************************************************************

File: app/templates/document-detail.html
********************************************************************************

{% extends "base.html" %}

{% macro render_json(key, value) %}
  <div class="info-section">
    <h2>{{ key|title }}</h2>
    {{ render_value(value) }}
  </div>
{% endmacro %}

{% macro render_value(value) %}
  {% if value is mapping %}
    <table class="info-table">
      {% for subkey, subvalue in value.items() %}
        <tr>
          <th>{{ subkey|title }}</th>
          <td>
            {{ render_value(subvalue) }}
          </td>
        </tr>
      {% endfor %}
    </table>
  {% elif value is iterable and value is not string %}
    <ul class="info-list">
      {% for item in value %}
        <li>
          {% if item is mapping %}
            <div class="nested-mapping">
              {% for itemkey, itemvalue in item.items() %}
                <strong>{{ itemkey|title }}:</strong> {{ render_value(itemvalue) }}<br>
              {% endfor %}
            </div>
          {% else %}
            {{ item }}
          {% endif %}
        </li>
      {% endfor %}
    </ul>
  {% else %}
    {{ value if value is not none else 'N/A' }}
  {% endif %}
{% endmacro %}

{% block styles %}
<style>
  .document-detail .detail-container {
    display: flex;
    gap: 20px;
  }

  .document-detail .info-panel {
    flex: 1;
    overflow-y: auto;
    max-height: calc(100vh - 40px);
  }

  .document-detail .image-panel {
    flex: 1;
    position: sticky;
    top: 20px;
    align-self: flex-start;
  }

  #imageContainer {
    width: 100%;
    height: auto;
    max-height: calc(100vh - 100px);
    overflow: auto;
    cursor: grab;
    position: relative;
  }

  #imageContainer.active {
    cursor: grabbing;
  }

  #documentImage {
    display: block;
    transform-origin: center;
  }

  .zoom-controls,
  .adjustment-controls {
    margin-top: 10px;
  }

  .zoom-controls button,
  .adjustment-controls button {
    margin-right: 5px;
    padding: 8px 12px;
    font-size: 14px;
  }

  .adjustment-controls label {
    margin-right: 10px;
  }

  .adjustment-controls input[type="range"] {
    vertical-align: middle;
    margin-right: 10px;
  }
</style>
{% endblock %}

{% block content %}
<div class="document-detail">
  <div class="detail-container">
    <div class="info-panel">
      <div class="navigation">
        <a href="{{ url_for('index') }}?return_to_search=true" class="nav-button" title="Return to Search Results">
            <span>Search</span>
        </a>
        <a href="{{ prev_id and url_for('document_detail', doc_id=prev_id, search_id=search_id) or '#' }}" class="nav-button {{ 'disabled' if not prev_id else '' }}" title="Previous Result">
            <span>Previous</span>
        </a>
        <a href="{{ url_for('index') }}" class="nav-button" title="Home">
            <span>Home</span>
        </a>
        <a href="{{ next_id and url_for('document_detail', doc_id=next_id, search_id=search_id) or '#' }}" class="nav-button {{ 'disabled' if not next_id else '' }}" title="Next Result">
            <span>Next</span>
        </a>
      </div>

      <h1>{{ document.get('filename', 'Untitled Document') }}</h1>

      <div class="info-container">
        {% for key, value in document.items() %}
          {% if key != '_id' and key != 'filename' %}
            {{ render_json(key, value) }}
          {% endif %}
        {% endfor %}
      </div>
    </div>

    <div class="image-panel">
      {% if image_exists %}
        <div id="imageContainer">
          <img id="documentImage" src="{{ url_for('serve_image', filename=image_path | urlencode) }}" alt="Document Image">
        </div>
        <div class="zoom-controls">
          <button id="rotateLeft">Rotate Left</button>
          <button id="rotateRight">Rotate Right</button>
          <button id="zoomIn">Zoom In</button>
          <button id="zoomOut">Zoom Out</button>
          <button id="resetZoom">Reset</button>
        </div>
        <div class="adjustment-controls">
          <label for="brightnessRange">Brightness:</label>
          <input type="range" id="brightnessRange" min="0.5" max="1.5" step="0.1" value="1">
          <label for="contrastRange">Contrast:</label>
          <input type="range" id="contrastRange" min="0.5" max="2" step="0.1" value="1">
          <label for="saturationRange">Saturation:</label>
          <input type="range" id="saturationRange" min="0" max="3" step="0.1" value="1">
          <label for="hueRange">Hue Rotation:</label>
          <input type="range" id="hueRange" min="0" max="360" step="10" value="0">
          <label for="blurRange">Blur:</label>
          <input type="range" id="blurRange" min="0" max="10" step="1" value="0">
          <button id="sharpenBtn">Sharpen</button>
          <button id="grayscaleBtn">Grayscale</button>
          <button id="sepiaBtn">Sepia</button>
          <button id="invertBtn">Invert Colors</button>
          <button id="flipHorizontalBtn">Flip Horizontal</button>
          <button id="flipVerticalBtn">Flip Vertical</button>
          <button id="resetAllBtn">Reset All</button>
        </div>
        <!-- Include SVG filter definitions for sharpening -->
        <svg width="0" height="0">
          <filter id="sharpen">
            <feConvolveMatrix order="3" kernelMatrix="0 -1 0 -1 5 -1 0 -1 0"></feConvolveMatrix>
          </filter>
        </svg>
      {% else %}
        <div class="placeholder-image">
          <p>Image not found: {{ image_path }}</p>
        </div>
      {% endif %}
    </div>
  </div>
</div>
{% endblock %}

{% block scripts %}
<script>
  document.addEventListener('DOMContentLoaded', () => {
    let scale = 1;
    let rotation = 0;
    const ZOOM_STEP = 0.1;
    const MAX_SCALE = 3;
    const MIN_SCALE = 0.5;

    // Variables for filters
    const brightnessRange = document.getElementById('brightnessRange');
    const contrastRange = document.getElementById('contrastRange');
    const saturationRange = document.getElementById('saturationRange');
    const hueRange = document.getElementById('hueRange');
    const blurRange = document.getElementById('blurRange');
    const sharpenBtn = document.getElementById('sharpenBtn');
    const grayscaleBtn = document.getElementById('grayscaleBtn');
    const sepiaBtn = document.getElementById('sepiaBtn');
    const invertBtn = document.getElementById('invertBtn');
    const flipHorizontalBtn = document.getElementById('flipHorizontalBtn');
    const flipVerticalBtn = document.getElementById('flipVerticalBtn');
    const resetAllBtn = document.getElementById('resetAllBtn');

    let isSharpened = false;
    let isGrayscale = false;
    let isSepia = false;
    let isInverted = false;
    let isFlippedHorizontal = false;
    let isFlippedVertical = false;

    const imageContainer = document.getElementById('imageContainer');
    const documentImage = document.getElementById('documentImage');
    const zoomInBtn = document.getElementById('zoomIn');
    const zoomOutBtn = document.getElementById('zoomOut');
    const resetZoomBtn = document.getElementById('resetZoom');
    const rotateLeftBtn = document.getElementById('rotateLeft');
    const rotateRightBtn = document.getElementById('rotateRight');

    function setImageTransform() {
      let transforms = [];

      // Scaling
      transforms.push(`scale(${scale})`);

      // Rotation
      transforms.push(`rotate(${rotation}deg)`);

      // Flipping
      const flipScaleX = isFlippedHorizontal ? -1 : 1;
      const flipScaleY = isFlippedVertical ? -1 : 1;
      transforms.push(`scale(${flipScaleX}, ${flipScaleY})`);

      documentImage.style.transform = transforms.join(' ');
    }

    function updateFilters() {
      let filters = [];

      // Brightness
      const brightnessValue = brightnessRange.value;
      filters.push(`brightness(${brightnessValue})`);

      // Contrast
      const contrastValue = contrastRange.value;
      filters.push(`contrast(${contrastValue})`);

      // Saturation
      const saturationValue = saturationRange.value;
      filters.push(`saturate(${saturationValue})`);

      // Hue Rotation
      const hueValue = hueRange.value;
      filters.push(`hue-rotate(${hueValue}deg)`);

      // Blur
      const blurValue = blurRange.value;
      filters.push(`blur(${blurValue}px)`);

      // Grayscale and Sepia
      if (isGrayscale) {
        filters.push(`grayscale(1)`);
      } else if (isSepia) {
        filters.push(`sepia(1)`);
      }

      // Invert
      if (isInverted) {
        filters.push(`invert(1)`);
      }

      // Apply Sharpen Filter if enabled
      if (isSharpened) {
        documentImage.style.filter = filters.join(' ') + ' url(#sharpen)';
      } else {
        documentImage.style.filter = filters.join(' ');
      }
    }

    function zoomIn() {
      if (scale < MAX_SCALE) {
        scale += ZOOM_STEP;
        setImageTransform();
      }
    }

    function zoomOut() {
      if (scale > MIN_SCALE) {
        scale -= ZOOM_STEP;
        setImageTransform();
      }
    }

    function resetZoom() {
      scale = 1;
      rotation = 0;
      setImageTransform();
    }

    function rotateLeft() {
      rotation -= 90;
      setImageTransform();
    }

    function rotateRight() {
      rotation += 90;
      setImageTransform();
    }

    zoomInBtn.addEventListener('click', zoomIn);
    zoomOutBtn.addEventListener('click', zoomOut);
    resetZoomBtn.addEventListener('click', resetZoom);
    rotateLeftBtn.addEventListener('click', rotateLeft);
    rotateRightBtn.addEventListener('click', rotateRight);

    // Event listeners for filters
    brightnessRange.addEventListener('input', updateFilters);
    contrastRange.addEventListener('input', updateFilters);
    saturationRange.addEventListener('input', updateFilters);
    hueRange.addEventListener('input', updateFilters);
    blurRange.addEventListener('input', updateFilters);

    sharpenBtn.addEventListener('click', () => {
      isSharpened = !isSharpened;
      updateFilters();
      sharpenBtn.textContent = isSharpened ? 'Unsharpen' : 'Sharpen';
    });

    grayscaleBtn.addEventListener('click', () => {
      isGrayscale = !isGrayscale;
      isSepia = false;
      updateFilters();
    });

    sepiaBtn.addEventListener('click', () => {
      isSepia = !isSepia;
      isGrayscale = false;
      updateFilters();
    });

    invertBtn.addEventListener('click', () => {
      isInverted = !isInverted;
      updateFilters();
    });

    flipHorizontalBtn.addEventListener('click', () => {
      isFlippedHorizontal = !isFlippedHorizontal;
      setImageTransform();
    });

    flipVerticalBtn.addEventListener('click', () => {
      isFlippedVertical = !isFlippedVertical;
      setImageTransform();
    });

    resetAllBtn.addEventListener('click', () => {
      // Reset transformations
      scale = 1;
      rotation = 0;
      isFlippedHorizontal = false;
      isFlippedVertical = false;
      setImageTransform();

      // Reset filters
      brightnessRange.value = 1;
      contrastRange.value = 1;
      saturationRange.value = 1;
      hueRange.value = 0;
      blurRange.value = 0;
      isSharpened = false;
      isGrayscale = false;
      isSepia = false;
      isInverted = false;
      updateFilters();

      // Reset button texts
      sharpenBtn.textContent = 'Sharpen';
    });

    // Dragging functionality
    let isDragging = false;
    let startX, startY, scrollLeft, scrollTop;

    imageContainer.addEventListener('mousedown', (e) => {
      isDragging = true;
      imageContainer.classList.add('active');
      startX = e.pageX - imageContainer.offsetLeft;
      startY = e.pageY - imageContainer.offsetTop;
      scrollLeft = imageContainer.scrollLeft;
      scrollTop = imageContainer.scrollTop;
    });

    imageContainer.addEventListener('mouseleave', () => {
      isDragging = false;
      imageContainer.classList.remove('active');
    });

    imageContainer.addEventListener('mouseup', () => {
      isDragging = false;
      imageContainer.classList.remove('active');
    });

    imageContainer.addEventListener('mousemove', (e) => {
      if (!isDragging) return;
      e.preventDefault();
      const x = e.pageX - imageContainer.offsetLeft;
      const y = e.pageY - imageContainer.offsetTop;
      const walkX = x - startX;
      const walkY = y - startY;
      imageContainer.scrollLeft = scrollLeft - walkX;
      imageContainer.scrollTop = scrollTop - walkY;
    });
  });
</script>
{% endblock %}


********************************************************************************

File: app/templates/document-list.html
********************************************************************************

<!-- templates/document-list.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Document List</title>
</head>
<body>
    <h1>Document List</h1>

    <ul id="documentList">
    {% for document in documents %}
        <li>
            <a href="{{ url_for('document_detail', doc_id=document['_id']) }}" target="_blank" rel="noopener noreferrer" class="document-link">{{ document.get('filename', 'Untitled Document') }}</a>
        </li>
    {% endfor %}
    </ul>
</body>
</html>


********************************************************************************

File: app/templates/base.html
********************************************************************************

<!-- templates/base.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>{% block title %}Historical Document Reader{% endblock %}</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <!-- Add this in the <head> section of base.html -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-yHnj4MvlYYKxE/6q9ZsH5mJ5RkJyKpjtXHYQVdG1Vl6HjnAsfsj0G9aJv1bQZoKEtZnSmhMWj58ZwFZJe61D1A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    {% block styles %}{% endblock %}
</head>
<body>
    <nav>
        <ul>
            <li><a href="{{ url_for('index') }}">Home</a></li>
            {% if session.get('logged_in') %}
                <li><a href="{{ url_for('logout') }}">Logout</a></li>
            {% else %}
                <li><a href="{{ url_for('login') }}">Login</a></li>
            {% endif %}
            <li><a href="{{ url_for('search_terms') }}">Search Terms</a></li>
            <li><a href="{{ url_for('database_info') }}">Database Info</a></li>
            <li><a href="{{ url_for('settings') }}">Settings</a></li>
        </ul>
    </nav>
    
    {% with messages = get_flashed_messages() %}
        {% if messages %}
            <ul class="flashes">
                {% for message in messages %}
                    <li>{{ message }}</li>
                {% endfor %}
            </ul>
        {% endif %}
    {% endwith %}
    
    {% block content %}{% endblock %}
    {% block scripts %}{% endblock %}
</body>
</html>


********************************************************************************

File: app/templates/database-info.html
********************************************************************************

<!-- templates/database-info.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Database Information</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="container">
        <h1>Database Information</h1>
        <nav>
            <ul>
                <li><a href="{{ url_for('index') }}">Home</a></li>
                <li><a href="{{ url_for('search_terms') }}">Search Terms</a></li>
                <li><a href="{{ url_for('database_info') }}">Database Info</a></li>
                <li><a href="{{ url_for('settings') }}">Settings</a></li>
            </ul>
        </nav>
        <table>
            <thead>
                <tr>
                    <th>Field Name</th>
                    <th>Number of Records</th>
                </tr>
            </thead>
            <tbody>
                {% for field in collection_info %}
                <tr>
                    <td>{{ field.name }}</td>
                    <td>{{ field.count }}</td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>
</body>
</html>


********************************************************************************

File: app/templates/settings.html
********************************************************************************

<!-- File: templates/settings.html -->

{% extends "base.html" %}

{% block content %}
<div class="container">
    <h1>Settings</h1>
    <form method="POST">
        <h2>Fonts</h2>
        <label for="fonts_main">Main Font:</label>
        <input type="text" id="fonts_main" name="fonts[main]" value="{{ config['fonts']['main'] }}"><br>
        <label for="fonts_headers">Headers Font:</label>
        <input type="text" id="fonts_headers" name="fonts[headers]" value="{{ config['fonts']['headers'] }}"><br>

        <h2>Sizes</h2>
        <label for="sizes_base">Base Size:</label>
        <input type="text" id="sizes_base" name="sizes[base]" value="{{ config['sizes']['base'] }}"><br>
        <label for="sizes_h1">H1 Size:</label>
        <input type="text" id="sizes_h1" name="sizes[h1]" value="{{ config['sizes']['h1'] }}"><br>
        <label for="sizes_h2">H2 Size:</label>
        <input type="text" id="sizes_h2" name="sizes[h2]" value="{{ config['sizes']['h2'] }}"><br>
        <label for="sizes_h3">H3 Size:</label>
        <input type="text" id="sizes_h3" name="sizes[h3]" value="{{ config['sizes']['h3'] }}"><br>

        <h2>Colors</h2>
        <label for="colors_primary">Primary Color:</label>
        <input type="color" id="colors_primary" name="colors[primary]" value="{{ config['colors']['primary'] }}"><br>
        <label for="colors_secondary">Secondary Color:</label>
        <input type="color" id="colors_secondary" name="colors[secondary]" value="{{ config['colors']['secondary'] }}"><br>
        <label for="colors_background">Background Color:</label>
        <input type="color" id="colors_background" name="colors[background]" value="{{ config['colors']['background'] }}"><br>
        <label for="colors_text">Text Color:</label>
        <input type="color" id="colors_text" name="colors[text]" value="{{ config['colors']['text'] }}"><br>

        <h2>Spacing</h2>
        <label for="spacing_small">Small Spacing:</label>
        <input type="text" id="spacing_small" name="spacing[small]" value="{{ config['spacing']['small'] }}"><br>
        <label for="spacing_medium">Medium Spacing:</label>
        <input type="text" id="spacing_medium" name="spacing[medium]" value="{{ config['spacing']['medium'] }}"><br>
        <label for="spacing_large">Large Spacing:</label>
        <input type="text" id="spacing_large" name="spacing[large]" value="{{ config['spacing']['large'] }}"><br>

        <button type="submit">Save Settings</button>
    </form>
</div>
<script>
    // Convert nested objects to JSON strings before form submission
    document.querySelector('form').addEventListener('submit', function(e) {
        ['fonts', 'sizes', 'colors', 'spacing'].forEach(function(key) {
            var inputs = document.querySelectorAll(`[name^="${key}\\["]`);
            var obj = {};
            inputs.forEach(function(input) {
                var prop = input.name.match(/\[(.*?)\]/)[1];
                obj[prop] = input.value;
            });
            var hiddenInput = document.createElement('input');
            hiddenInput.type = 'hidden';
            hiddenInput.name = key;
            hiddenInput.value = JSON.stringify(obj);
            this.appendChild(hiddenInput);
        }, this);
    });
</script>
{% endblock %}


********************************************************************************

File: app/templates/index.html
********************************************************************************

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Historical Document Reader</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Open+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <div class="container">
        <h1 class="mt-4">Historical Document Reader</h1>
        <nav>
            <ul>
                <li><a href="{{ url_for('index') }}">Home</a></li>
                <li><a href="{{ url_for('search_terms') }}">Search Terms</a></li>
                <li><a href="{{ url_for('database_info') }}">Database Info</a></li>
                <li><a href="{{ url_for('settings') }}">Settings</a></li>
                {% if 'logged_in' in session %}
                    <li><a href="{{ url_for('logout') }}">Logout</a></li>
                {% else %}
                    <li><a href="{{ url_for('login') }}">Login</a></li>
                {% endif %}
            </ul>
        </nav>

        <form id="searchForm">
            <div id="searchFields">
                {% for i in range(1, num_search_fields + 1) %}
                <div class="search-field">
                    <label for="field{{ i }}">Field:</label>
                    <select name="field{{ i }}" id="field{{ i }}">
                        <option value="" disabled selected>Select a field</option>
                        {% for field in field_structure|dictsort %}
                            <option value="{{ field[0] }}">{{ field[0] }}</option>
                        {% endfor %}
                    </select>
                    <label for="operator{{ i }}">Operator:</label>
                    <select name="operator{{ i }}" id="operator{{ i }}">
                        <option value="AND">AND</option>
                        <option value="OR">OR</option>
                        <option value="NOT">NOT</option>
                    </select>
                    <label for="searchTerm{{ i }}">Search Term:</label>
                    <input type="text" name="searchTerm{{ i }}" id="searchTerm{{ i }}" placeholder="Enter search term">
                </div>
                {% endfor %}
            </div>
            <button type="submit" id="searchButton">Search</button>
            <!-- Export Selected to CSV Button -->
            <button id="exportSelectedCsv" style="display: none; margin-top: 10px;">Export Selected to CSV</button>
        </form>

        <!-- Loading Indicator -->
        <div id="loadingIndicator" style="display: none;">
            <div class="spinner"></div>
            <p>Loading... Please wait.</p>
        </div>

        <!-- Cancel Search Button -->
        <button id="cancelSearch" style="display: none;">Cancel Search</button>

        <!-- Total Results Display -->
        <div id="totalResults" class="mt-4"></div>

        <!-- Results Container -->
        <div id="results" class="mt-4">
            <!-- The table will be dynamically inserted here -->
        </div>

        
    </div>

    <!-- Include jQuery -->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <!-- Include your custom script -->
    <script src="{{ url_for('static', filename='script.js') }}"></script>
</body>
</html>


********************************************************************************

File: app/templates/error.html
********************************************************************************

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Error</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>
    <h1>Error</h1>
    <p>{{ message }}</p>
    <a href="{{ url_for('index') }}">Return to Home</a>
</body>
</html>


********************************************************************************

File: app/static/script.js
********************************************************************************

document.addEventListener('DOMContentLoaded', function() {
    // ===============================
    // Initialization
    // ===============================
    const searchForm = document.getElementById('searchForm');
    const resultsDiv = document.getElementById('results');
    const loadingIndicator = document.getElementById('loadingIndicator');
    const cancelButton = document.getElementById('cancelSearch');
    const totalResultsDiv = document.getElementById('totalResults');
    const exportSelectedCsvButton = document.getElementById('exportSelectedCsv');

    // Add console warnings for missing elements
    if (!searchForm) console.warn('Search form not found');
    if (!resultsDiv) console.warn('Results div not found');
    if (!loadingIndicator) console.warn('Loading indicator not found');
    if (!cancelButton) console.warn('Cancel button not found');
    if (!totalResultsDiv) console.warn('Total results div not found');
    if (!exportSelectedCsvButton) console.warn('Export Selected CSV button not found');

    // Pagination and Search Variables
    let controller;
    let page = 1;
    let totalPages = 1;
    const perPage = 50;  // Fixed number of results per request
    let totalResults = 0;
    let isLoading = false;
    let hasMore = true;
    let currentQuery = {};
    let prefetchedData = null;

    // Selection Management
    let selectedDocuments = new Set();

    // Variable to store current search_id
    let searchId = null;

    // ===============================
    // Utility Functions
    // ===============================

    /**
     * Debounce function to limit the rate at which a function can fire.
     * @param {Function} func - The function to debounce.
     * @param {number} delay - The delay in milliseconds.
     * @returns {Function} - The debounced function.
     */
    function debounce(func, delay) {
        let timeoutId;
        return function(...args) {
            clearTimeout(timeoutId);
            timeoutId = setTimeout(() => func.apply(this, args), delay);
        };
    }

    /**
     * Toggles the selection of a document.
     * @param {string} docId - The ID of the document.
     * @param {boolean} isSelected - Whether the document is selected.
     */
    function toggleDocumentSelection(docId, isSelected) {
        if (isSelected) {
            selectedDocuments.add(docId);
        } else {
            selectedDocuments.delete(docId);
        }
        updateExportButtonVisibility();
        saveSelectedDocuments();
    }

    /**
     * Updates the visibility of the Export Selected button based on selections.
     */
    function updateExportButtonVisibility() {
        if (!exportSelectedCsvButton) return;
        if (selectedDocuments.size > 0) {
            exportSelectedCsvButton.style.display = 'inline-block';
        } else {
            exportSelectedCsvButton.style.display = 'none';
        }
    }

    /**
     * Saves the selected documents to localStorage.
     */
    function saveSelectedDocuments() {
        localStorage.setItem('selectedDocuments', JSON.stringify(Array.from(selectedDocuments)));
    }

    /**
     * Loads the selected documents from localStorage.
     */
    function loadSelectedDocuments() {
        const savedSelectedDocuments = JSON.parse(localStorage.getItem('selectedDocuments') || '[]');
        savedSelectedDocuments.forEach(id => selectedDocuments.add(id));
        updateExportButtonVisibility();
    }

    /**
     * Shows the loading indicator.
     */
    function showLoadingIndicator() {
        if (loadingIndicator && loadingIndicator.style) {
            loadingIndicator.style.display = 'block';
        }
    }

    /**
     * Hides the loading indicator.
     */
    function hideLoadingIndicator() {
        if (loadingIndicator && loadingIndicator.style) {
            loadingIndicator.style.display = 'none';
        }
    }

    /**
     * Resets the search parameters and UI elements.
     */
    function resetSearch() {
        page = 1;
        hasMore = true;
        if (resultsDiv) resultsDiv.innerHTML = '';
        if (totalResultsDiv) totalResultsDiv.textContent = '';
        searchId = null;  // Reset search_id for new search
    }

    /**
     * Gathers search parameters from the form.
     */
    function gatherSearchParameters() {
        const formData = new FormData(searchForm);
        currentQuery = {};
        for (let i = 1; i <= 3; i++) {
            currentQuery[`field${i}`] = formData.get(`field${i}`);
            currentQuery[`operator${i}`] = formData.get(`operator${i}`);
            currentQuery[`searchTerm${i}`] = formData.get(`searchTerm${i}`);
        }
    }

    /**
     * Validates the search parameters.
     * @returns {boolean} True if valid, else false.
     */
    function validateSearchParameters() {
        if (!currentQuery['field1'] || !currentQuery['searchTerm1']) {
            console.error('Please enter a valid search term in the first field.');
            alert('Please enter a valid search term in the first field.');
            return false;
        }
        return true;
    }

    /**
     * Handles the scroll event for infinite scrolling.
     */
    function handleScroll() {
        const scrollPosition = window.innerHeight + window.scrollY;
        const threshold = document.body.offsetHeight - 100;

        if (scrollPosition >= threshold) {
            if (prefetchedData) {
                // Use prefetched data
                appendResults(prefetchedData.documents);
                page += 1;
                totalPages = prefetchedData.total_pages;
                totalResults = prefetchedData.total_count;
                updateTotalResults();

                // Clear prefetched data and prefetch the next page
                prefetchedData = null;
                if (page <= totalPages) {
                    prefetchNextPage();
                } else {
                    hasMore = false;
                }
            } else {
                performSearch();
            }
        } else if (prefetchedData === null && (scrollPosition >= threshold / 2)) {
            // Start prefetching when user scrolls halfway
            prefetchNextPage();
        }
    }

    // ===============================
    // Event Listeners
    // ===============================

    // Handle form submission for search
    if (searchForm) {
        searchForm.addEventListener('submit', function(e) {
            e.preventDefault();
            resetSearch();
            gatherSearchParameters();
            if (validateSearchParameters()) {
                performSearch(true);
            }
        });
    }

    // Handle checkbox changes using event delegation
    if (resultsDiv) {
        resultsDiv.addEventListener('change', function(e) {
            if (e.target && e.target.matches('.select-document')) {
                const docId = e.target.getAttribute('data-doc-id');
                toggleDocumentSelection(docId, e.target.checked);
            }
        });
    }

    // Handle "Select All" functionality
    if (resultsDiv) {
        resultsDiv.addEventListener('change', function(e) {
            if (e.target && e.target.matches('#selectAll')) {
                const checkboxes = resultsDiv.querySelectorAll('.select-document');
                const isChecked = e.target.checked;
                checkboxes.forEach(cb => {
                    cb.checked = isChecked;
                    const docId = cb.getAttribute('data-doc-id');
                    if (isChecked) {
                        selectedDocuments.add(docId);
                    } else {
                        selectedDocuments.delete(docId);
                    }
                });
                updateExportButtonVisibility();
                saveSelectedDocuments();
            }
        });
    }

    // Handle Export Selected to CSV Button Click
    if (exportSelectedCsvButton) {
        exportSelectedCsvButton.addEventListener('click', function() {
            exportSelectedDocuments();
        });
    }

    // Handle Cancel Search Button Click
    if (cancelButton) {
        cancelButton.addEventListener('click', function() {
            cancelSearch();
        });
    }

    // Handle Infinite Scroll with Debounce
    window.addEventListener('scroll', debounce(handleScroll, 200));

    // ===============================
    // Search Functionality
    // ===============================

    /**
     * Performs the search by sending a POST request to the server.
     * @param {boolean} isNewSearch - Indicates if it's a new search.
     */
    function performSearch(isNewSearch = false) {
        if (isLoading || !hasMore) return;
        isLoading = true;

        if (isNewSearch) {
            prefetchedData = null;
            searchId = null;  // Reset search_id for new search
        }

        showLoadingIndicator();
        if (cancelButton) cancelButton.style.display = 'inline-block';

        // Add page and perPage to currentQuery
        currentQuery.page = page;
        currentQuery.per_page = perPage;

        controller = new AbortController();
        const signal = controller.signal;

        fetch('/search', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(currentQuery),
            signal: signal
        })
        .then(response => response.json())
        .then(data => {
            hideLoadingIndicator();
            if (cancelButton) cancelButton.style.display = 'none';
            if (data.documents && data.documents.length > 0) {
                // Store search_id if it's a new search
                if (isNewSearch) {
                    searchId = data.search_id;
                }

                appendResults(data.documents);
                totalPages = data.total_pages;
                totalResults = data.total_count;

                // Prefetch the next page if there are more pages
                if (page < totalPages) {
                    page += 1;
                    prefetchNextPage();
                } else {
                    hasMore = false;
                }
            } else {
                hasMore = false;
                if (isNewSearch && resultsDiv && resultsDiv.innerHTML === '') {
                    resultsDiv.innerHTML = '<p>No results found.</p>';
                }
            }
            updateTotalResults();
            isLoading = false;
        })
        .catch(error => {
            hideLoadingIndicator();
            if (cancelButton) cancelButton.style.display = 'none';
            isLoading = false;
            if (error.name === 'AbortError') {
                console.log('Search was cancelled');
            } else {
                console.error('Error:', error);
                alert('An error occurred during the search. Please try again.');
            }
        });
    }

    /**
     * Appends search results to the resultsDiv.
     * @param {Array} documents - List of document objects.
     */
    function appendResults(documents) {
        if (!resultsDiv) return;

        let table = document.getElementById('resultsTable');
        let tbody;

        // If the table doesn't exist yet, create it
        if (!table) {
            table = document.createElement('table');
            table.id = 'resultsTable';

            // Create table headers with a Select All checkbox
            const thead = document.createElement('thead');
            thead.innerHTML = `
                <tr>
                    <th><input type="checkbox" id="selectAll" /></th>
                    <th>File</th>
                    <th>Summary</th>
                </tr>
            `;
            table.appendChild(thead);

            // Create table body
            tbody = document.createElement('tbody');
            table.appendChild(tbody);

            // Append the table to the results div
            resultsDiv.appendChild(table);
        } else {
            // If the table exists, get its tbody
            tbody = table.querySelector('tbody');
        }

        // Append new rows to the table body
        documents.forEach(doc => {
            const row = document.createElement('tr');
            row.innerHTML = `
                <td><input type="checkbox" class="select-document" data-doc-id="${doc._id}" /></td>
                <td><a href="/document/${doc._id}?search_id=${searchId}">${doc.filename || 'No file name'}</a></td>
                <td>${doc.summary || 'No summary available.'}</td>
            `;
            // If the document is already selected, check the box
            if (selectedDocuments.has(doc._id)) {
                row.querySelector('.select-document').checked = true;
            }
            tbody.appendChild(row);
        });
    }

    /**
     * Updates the total results display.
     */
    function updateTotalResults() {
        if (totalResultsDiv) {
            totalResultsDiv.textContent = `Total results: ${totalResults}`;
        }
    }

    /**
     * Prefetches the next page of results.
     */
    function prefetchNextPage() {
        if (prefetchedData || !hasMore) return;

        const prefetchQuery = { ...currentQuery, page: page };

        fetch('/search', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(prefetchQuery),
        })
        .then(response => response.json())
        .then(data => {
            if (data.documents && data.documents.length > 0) {
                prefetchedData = data;
            } else {
                hasMore = false;
            }
        })
        .catch(error => {
            console.error('Error during prefetching:', error);
        });
    }

    // ===============================
    // Selection Management
    // ===============================

    /**
     * Exports the selected documents to CSV.
     */
    function exportSelectedDocuments() {
        if (selectedDocuments.size === 0) {
            alert('No documents selected.');
            return;
        }

        // Prepare the list of selected document IDs
        const selectedIds = Array.from(selectedDocuments);

        // Show a loading modal or notification
        showExportModal('Exporting selected documents...');

        // Send the list to the server via POST
        fetch('/export_selected_csv', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ document_ids: selectedIds }),
        })
        .then(response => {
            if (response.ok) {
                return response.blob();
            } else {
                return response.json().then(err => { throw err; });
            }
        })
        .then(blob => {
            // Create a link to download the blob
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'selected_documents.csv';
            document.body.appendChild(a);
            a.click();
            a.remove();
            window.URL.revokeObjectURL(url);

            // Hide the export modal and show success message
            hideExportModal();
            showExportModal('Export successful!', 'success');

            // Reset the export button
            exportSelectedCsvButton.disabled = false;
            exportSelectedCsvButton.textContent = 'Export Selected to CSV';

            // Optionally, clear the selectedDocuments set
            selectedDocuments.clear();
            updateExportButtonVisibility();

            // Uncheck all checkboxes
            const checkboxes = resultsDiv.querySelectorAll('.select-document');
            checkboxes.forEach(cb => cb.checked = false);

            // Uncheck "Select All" checkbox
            const selectAllCheckbox = document.getElementById('selectAll');
            if (selectAllCheckbox) {
                selectAllCheckbox.checked = false;
            }

            // Remove success message after a short delay
            setTimeout(() => {
                hideExportModal();
            }, 3000);
        })
        .catch(error => {
            console.error('Error exporting selected documents:', error);
            hideExportModal();
            alert('Error exporting selected documents.');

            // Reset the export button
            exportSelectedCsvButton.disabled = false;
            exportSelectedCsvButton.textContent = 'Export Selected to CSV';
        });
    }

    /**
     * Cancels the ongoing search.
     */
    function cancelSearch() {
        if (controller) {
            controller.abort();
            hideLoadingIndicator();
            isLoading = false;
            hasMore = false;
            if (cancelButton) cancelButton.style.display = 'none';
        }
    }

    // ===============================
    // Export Feedback Mechanism
    // ===============================

    /**
     * Creates and displays an export modal for feedback.
     * @param {string} message - The message to display.
     * @param {string} type - The type of message ('info', 'success', 'error').
     */
    function showExportModal(message, type = 'info') {
        // Check if modal already exists
        let modal = document.getElementById('exportModal');
        if (!modal) {
            modal = document.createElement('div');
            modal.id = 'exportModal';
            modal.innerHTML = `
                <div class="modal-content">
                    <span class="close-button">&times;</span>
                    <p id="exportMessage">${message}</p>
                </div>
            `;
            document.body.appendChild(modal);

            // Style the modal
            const style = document.createElement('style');
            style.textContent = `
                #exportModal {
                    display: block; 
                    position: fixed; 
                    z-index: 1000; 
                    left: 0;
                    top: 0;
                    width: 100%; 
                    height: 100%; 
                    overflow: auto; 
                    background-color: rgba(0,0,0,0.4); 
                }
                .modal-content {
                    background-color: #fefefe;
                    margin: 15% auto; 
                    padding: 20px;
                    border: 1px solid #888;
                    width: 300px; 
                    text-align: center;
                    border-radius: 5px;
                }
                .close-button {
                    color: #aaa;
                    float: right;
                    font-size: 28px;
                    font-weight: bold;
                    cursor: pointer;
                }
                .close-button:hover,
                .close-button:focus {
                    color: black;
                    text-decoration: none;
                }
                .modal-content.success {
                    border-color: #28a745;
                }
                .modal-content.error {
                    border-color: #dc3545;
                }
            `;
            document.head.appendChild(style);

            // Handle close button click
            modal.querySelector('.close-button').addEventListener('click', hideExportModal);
        }

        // Update the message and style based on type
        const exportMessage = modal.querySelector('#exportMessage');
        exportMessage.textContent = message;
        modal.querySelector('.modal-content').className = 'modal-content'; // Reset classes

        if (type === 'success') {
            modal.querySelector('.modal-content').classList.add('success');
        } else if (type === 'error') {
            modal.querySelector('.modal-content').classList.add('error');
        }

        // Display the modal
        modal.style.display = 'block';
    }

    /**
     * Hides the export modal.
     */
    function hideExportModal() {
        const modal = document.getElementById('exportModal');
        if (modal) {
            modal.style.display = 'none';
        }
    }

    // ===============================
    // Initial Load
    // ===============================

    // Load selected documents from localStorage
    loadSelectedDocuments();
});


********************************************************************************

File: app/static/style.css
********************************************************************************

/* static/style.css */

/* Base Styles */
body {
    font-family: 'Open Sans', sans-serif;
    font-size: 16px;
    line-height: 1.6;
    background-color: #ffffff;
    color: #333;
    margin: 0;
    padding: 0;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

h1, h2, h3 {
    font-family: 'Montserrat', sans-serif;
    color: #333;
    margin-bottom: 20px;
}

/* Navigation */
nav ul {
    list-style-type: none;
    padding: 0;
    display: flex;
    gap: 15px;
    margin-bottom: 20px;
}

nav ul li {
    display: inline;
}

nav ul li a {
    text-decoration: none;
    color: #007bff;
    font-weight: bold;
}

nav ul li a:hover {
    text-decoration: underline;
}

/* Flash Messages */
.flashes {
    list-style-type: none;
    padding: 0;
    color: red;
}

/* Search Form */
.search-field {
    display: flex;
    gap: 10px;
    margin-bottom: 15px;
    align-items: center;
}

input[type="text"], select {
    padding: 10px;
    border: 1px solid #ccc;
    border-radius: 4px;
    font-size: 16px;
}

button {
    padding: 10px 20px;
    background-color: #007bff;
    color: #fff;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    transition: background-color 0.3s ease;
    font-size: 16px;
}

button:hover {
    background-color: #0056b3;
}

/* Navigation Buttons */
.nav-button {
    display: inline-block;
    padding: 8px 12px;
    margin-right: 5px;
    background-color: #007bff;
    color: #fff;
    text-decoration: none;
    border-radius: 4px;
    transition: background-color 0.3s ease;
    font-size: 14px;
    text-align: center;
}

.nav-button:hover {
    background-color: #0056b3;
}

.nav-button.disabled {
    background-color: #6c757d;
    pointer-events: none;
    cursor: default;
}

/* Results Table */
#results table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 20px;
}

#results th, #results td {
    padding: 12px;
    text-align: left;
    border-bottom: 1px solid #ddd;
}

#results th {
    background-color: #f0f0f0;
    font-weight: bold;
}

#results tbody tr:nth-child(odd) {
    background-color: #f9f9f9;
}

#results tbody tr:nth-child(even) {
    background-color: #ffffff;
}

#results tbody tr:hover {
    background-color: #eaeaea;
}

#results a {
    color: #007bff;
    text-decoration: none;
}

#results a:hover {
    text-decoration: underline;
}

/* Loading Indicator */
#loadingIndicator {
    text-align: center;
    margin-top: 20px;
}

.spinner {
    border: 4px solid #f3f3f3;
    border-top: 4px solid #3498db;
    border-radius: 50%;
    width: 40px;
    height: 40px;
    animation: spin 1s linear infinite;
    margin: 0 auto;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

/* Additional Styles */
.mt-4 {
    margin-top: 1rem;
}

.ml-auto {
    margin-left: auto;
}

/* Error Messages */
.error {
    color: #dc3545;
    font-weight: bold;
}

/* Document Detail Styles */
.document-detail .detail-container {
    display: flex;
    gap: 20px;
}

.document-detail .info-panel {
    flex: 1;
}

.document-detail .image-panel {
    flex: 1;
    position: relative;
}

#imageContainer {
    overflow: auto;
    max-width: 100%;
    max-height: 600px;
}

#documentImage {
    max-width: 100%;
    max-height: 100%;
    transform-origin: top left;
}

.zoom-controls {
    margin-top: 10px;
}

.zoom-controls button {
    margin-right: 5px;
}

.info-section {
    margin-bottom: 20px;
    border: 1px solid #e0e0e0;
    border-radius: 5px;
    padding: 15px;
}

.info-table, .nested-table {
    width: 100%;
    border-collapse: collapse;
}

.info-table th, .info-table td,
.nested-table th, .nested-table td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: left;
}

.info-table th, .nested-table th {
    background-color: #f2f2f2;
}

.nested-list, .info-list {
    list-style-type: none;
    padding-left: 0;
}

.nested-list li, .info-list li {
    margin-bottom: 10px;
}


********************************************************************************

